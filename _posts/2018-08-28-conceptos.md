---
layout: post
section-type: post
title: Conceptos generales
category: PrimerPeriodo
tags: [ 'información' , 'datos', 'computadoras', 'binario', 'bit']
---

### Presentación electronica

 <div style="position: relative;
            padding-bottom: 56.25%;
            height: 0;
            overflow: hidden;">
<iframe style="position: absolute;
                 top:0;
                 left: 0;
                 width: 100%;
                 height: 100%;" width="550" height="400" src="https://marcoc76.github.io/musical-pancake/conceptos.html"></iframe></div><br>

[Pantalla completa](https://marcoc76.github.io/musical-pancake/conceptos.html "Presentación en pantalla completa")

Informática es una palabra que involucra en su estructura semántica dos
términos: información y automática. Se acuñó en Francia hace 40 años con
la intención de definir el conjunto de procedimientos, métodos, técnicas
y otros aspectos científicos de diferentes áreas que se venían
desarrollando y aplicando al tratamiento de la información con el uso de
las computadoras para resolver problemas económicos, sociales y
políticos.

Para definirla decimos que: “Informática es la sistematización racional
de la información”. Consideramos que esta definición ubica a la
informática en una actitud más próxima a una ciencia y en torno a la
información, pero siempre tratada ésta en forma de sistema o sistemas.
Es decir, sistematizar la información es la función básica de la
informática, pero deberá hacerse racionalmente, de lo contrario la
función es incompleta.

Es obvio que para sistematizar la información es necesario el uso de
herramientas que van desde el papel y el lápiz hasta las computadoras
más sofisticadas, dependiendo del volumen de datos que se maneje para
generar la información y los procedimientos que se establezcan para el
procesamiento de los datos.

En Estados Unidos no es muy conocido el término, que se toma como
sinónimo de information technology  (IT) .

### Conceptos importantes 

#### CIENCIA

En su definición más amplia, es el conocimiento ordenado que se utiliza
para organizar experiencias y confirmarlas de manera objetiva. Se puede
dividir en dos partes: una es la ciencia pura, que es la búsqueda del
conocimiento, la otra es la ciencia aplicada, que es la búsqueda de usos
útiles para los conocimientos adquiridos.

#### TECNOLOGÍA

Es el proceso que le permite a los seres humanos diseñar herramientas y
máquinas para controlar su ambiente material y aumentar la comprensión
de este.

El término proviene de dos palabras griegas: tecné, que significa “arte”
u “oficio”, y logos, que significa “conocimiento” o “tratado”.

En conclusión, la tecnología es el conocimiento de los oficios.

#### DATOS

Conjunto de símbolos que representan la información de manera que se
permita su procesamiento.

Los datos son elementos simples, que al ser interpretados y
relacionados, adquieren un sentido, un significado. Por lo tanto, se
transforman en información. La diferencia entre datos e información
existe sólo para las personas; para la computadora sólo son  elementos
de entrada y elementos de salida.

En el contexto informático, los datos se refieren a los elementos crudos
que la computadora puede utilizar (las computadoras trabajan los datos
de muchas maneras), a esta acción se le denomina procesamiento. Los
datos pueden consistir en números, letras, sonidos o imágenes que sirven
para describir hechos sobre algo, y una vez que son procesados por la
computadora, se convierten en información. A la serie de instrucciones
que indica a una computadora cómo realizar las tareas de procesamiento
se le llama programa.

#### INFORMACIÓN

El matemático estadounidense Claude E. Shannon es el creador de la
“teoría moderna de la información”. De acuerdo con él, la información es
todo lo que reduce la incertidumbre entre varias alternativas posibles.
Son los datos que necesitamos conocer para tomar decisiones de manera
más efectiva.

Como lo ha sido siempre, la información es considerada un valioso
recurso empresarial y de poder, por lo que la informática ha ocupado un
lugar imprescindible en las actividades humanas y la comunicación,
incluyendo las definiciones, usos y distribución de la información.

Pongamos algunos ejemplos: el color rojo de un semáforo constituye una
información, ya que tiene una interpretación específica y universal para
un grupo de personas (los automovilistas), y les sirve como apoyo para
tomar una decisión: detener el automóvil. Otro ejemplo de información
podría ser la fecha de cumpleaños de algún familiar o  allegado, ya que
esta fecha tiene, en forma subjetiva, un valor que se traduce a acciones
o actividades. En un contexto de negocios, las utilidades consolidadas
del mes anterior después de fletes y comisiones, son de \$120,000.00.
Esto es información porque apoya en el proceso de toma de decisiones.

#### INFORMÁTICA

Es la ciencia de la información. El término se forma de la combinación
de las palabras información y automática. Por tanto, es el conjunto de
conocimientos que permiten el tratamiento automático de la información y
se utiliza para abarcar a todo lo relacionado con el manejo de datos
mediante equipos de procesamiento automático como las computadoras.

La informática tiene que ver con la programación, la arquitectura de las
computadoras, la inteligencia y la robótica, entre otros temas.

### Campo de aplicación de la tecnología 

Todo el desarrollo tecnológico que hemos sufrido en estas últimas
décadas ha permitido que las tecnologías de la información y la
comunicación (TIC) se introduzcan en nuestros entornos laborales, a
menudo transformando considerablemente los tipos y formas de trabajo que
las personas realizan.

Cada vez se han hecho más fáciles de utilizar los sistemas de cómputo y
poco a poco ha cobrado su importancia en la inclusión laboral. Y como
bien es sabido, las TIC siguen desarrollándose día a día y por
consiguiente cada vez van adoptando nuevas áreas de aplicación.

Los campos de aplicación de la informática son tan variados y diversos
que el hecho de tratar de citarlos a todos se convertiría una lista
interminable. A continuación se citan lo más representativos:

#### Comunicación 

La tecnología electrónica, con sus microprocesadores, memorias de
capacidad cada vez más elevada y circuitos integrados, hace que los
cambios en el sector de las comunicaciones puedan asociarse a los de las
computadoras. La evolución tecnológica moderna ha desempeñado un papel
clave en el desarrollo de las modernas telecomunicaciones; la
microelectrónica, por ejemplo, con la miniaturización de los
componentes, la reducción de los costos de fabricación y el aumento de
la fiabilidad de los dispositivos, ha permitido una incorporación masiva
de las técnicas digitales a los equipos de telecomunicación.

La importancia de la digitalización de dichos equipos radica, sobre
todo, en una mejoría notable de la calidad de los servicios ofrecidos. A
este respecto cabe destacar las telecomunicaciones a través de fibra
óptica y los enlaces que se establecen gracias a los satélites de
comunicación. Es fácil darnos cuenta cómo el desarrollo de la
computación y la informática se ha integrado en las telecomunicaciones y
ha propiciado el surgimiento de nuevas formas de comunicación, que son
aceptadas y usadas cada vez por más personas.

#### Educación

La "sociedad de la información" en general y las nuevas tecnologías en
particular, inciden de manera significativa estudiante necesita así como
también se brindan recursos mediante los cuales el estudiante pregunta a
su instructor por correo electrónico todas sus dudas y también puede
hacerlo en tiempo real o por mensajería instantánea. Esto incluye
exámenes oficiales que el alumno debe aprobar para avanzar al siguiente
nivel. También puede hacerse una combinación entre lo virtual y lo
físico, pues normalmente un programa formal de educación a distancia,
envía también material impreso de las clases o documentos que el alumno
necesita y permite estar en contacto mediante el correo postal como una
opción adicional. Al final, el estudiante obtiene el Diploma o Título
certificado que le acredita luego de haber realizado sus estudios a
distancia, donde se hace uso de las tecnologías informáticas.

El sector educativo ha dado un gran salto positivo gracias a la llegada
de las computadoras, incluso cuando para algunos existen ciertas
desventajas como por ejemplo que el estudiante no trabaja diligentemente
para encontrar la información sino que se vuelve demasiado cómodo, etc.

Pero a pesar de todo, nadie puede negar que la computación ha venido a
beneficiar en gran manera el sector educativo, proporcionando los
recursos para que todos estar informados y podamos de esa forma
incrementar nuestros conocimientos en cada una de las ramas a las cuales
nos dedicamos en particular.

Lo más importante es saber orientar los recursos y oportunidades que
tenemos actualmente, pues los grandes saltos que se han dado en los
últimos años en el desarrollo informático, debe beneficiar e impactar
positivamente la metodología educativa y de aprendizaje en todos los
niveles de enseñanza, desde los niños en las edades escolares hasta las
universidades y estudios avanzados. No cabe duda que la computación
 está abriendo nuevas posibilidades de conocimiento y desarrollo
educativo a nivel mundial.

#### Internet

Internet es el resultado de la conexión de miles de redes informáticas
ya existentes, por eso se le ha llamado también la red de redes. Unos
protocolos de comunicación adecuados permiten que cualquiera de los
usuarios que navegan por una de estas redes interconectadas puedan
acceder sin problemas a las otras y, de este modo, enviar mensajes y
recibir informaciones de otros usuarios. Desde el momento en que
entramos a Internet y nos conectamos a un servidor, esto es, a una
computadora que nos sirve de vía de acceso a la red, podemos utilizarla
para llegar a otros servidores y aprovechar, de manera interactiva, los
servicios que nos ofrecen. Asimismo, se pueden enviar mensajes vía
correo electrónico o mensajería instantánea, tanto a los usuarios de
Internet como a los de redes ajenas a ella. Además, quien se adentra en
la red dispone de innumerables servicios tales como acceso a las más
diversas bases de datos alimentadas con informaciones concretas o con
programas, guías de introducción a la propia red, catálogos de productos
y servicios, informaciones de centros oficiales, etcétera.

#### Aplicaciones ofimáticas 

Existen en el campo de la computación unas aplicaciones de carácter
general, es decir, que se utilizan en muchos campos, como el de la
industria, la enseñanza, los deportes, etcétera. Básicamente, estas
aplicaciones constan de cuatro apartados: Procesadores de textos, hojas
electrónicas o de cálculo, gráficos y tablas, bases de datos y
presentaciones. Hay una tendencia a comercializar paquetes integrados
que contienen, como mínimo, estos cuatro apartados; sin embargo, también
se pueden encontrar estas aplicaciones por separado.

#### Comercio

Las computadoras también han llegado al mundo de los negocios y del
comercio, realizando funciones no sólo de cajas registradoras, sino
también de herramientas para almacenar datos, calcular costos, mantener
almacenes al día, etcétera. Permiten, en definitiva, llevar este tipo de
empresas de una manera más organizada y tener siempre una visión de
conjunto lo más aproximada posible a la realidad, con todos los datos al
día, y poder hacer un cálculo muy exacto de su rentabilidad. El análisis
de esta situación ha llevado a los fabricantes de cajas registradoras y
de computadoras a desarrollar y ofrecer soluciones computacionales para
facilitar la gestión de los negocios, permitiendo comparar mejor,
adecuar los productos ofrecidos a la demanda, anular los productos que
tengan poca salido o rotación y optimizar el inventario para que se
produzca menor cantidad de material inmovilizado.

#### Arquitectura, diseño, construcción

Otros campos con gran aplicación de la computación son el diseño
asistido por computadora (CAD) y la fabricación asistida por computadora
(CAM). Los efectos se multiplican cuando actúan simultáneamente. La
utilización de la computadora en estos procesos surgió en las grandes
compañías americanas para reducir los costos de producción. Las
herramientas reprogramables son máquinas capaces de fabricar diferentes
piezas con sólo pequeños cambios y ajustes (por ejemplo, un soldador
automático); estos cambios y ajustes se reducen a la secuencia de
órdenes que se han de ejecutar (moverse dos centímetros a la izquierda,
soldar, etc.). Se trata de pequeñas computadoras especializadas en unas
acciones determinadas. El impacto de la informática en este campo es
enorme, permitiendo la creación de plantas de producción totalmente
automatizadas.

Otro aspecto fundamental de los procesos CAD/CAM es el diseño asistido
por computadora. Se utiliza para desarrollar un nuevo diseño en un
tiempo mínimo o la modificación rápida de otro ya existente. La
computadora se transforma en una herramienta que permite al diseñador
manipular dibujos que, con los procedimientos tradicionales, serían más
largos y costosos de realizar. Una vez realizado el plano o dibujo en la
pantalla de la computadora, puede guardarse permanentemente en una
memoria e incluso imprimirse usando un plotter aparato dedicado a la
impresión de dibujos). Una vez almacenado, el dibujo puede modificarse
cuantas veces se quiera, sin necesidad de dibujarlo de nuevo. La rápida
disponibilidad de los planos modificados permite agilizar los procesos
industriales, proporcionando así una mayor productividad.

Estas técnicas de diseño y producción mediante computadoras (CAD/CAM)
hacen posible también que una misma cadena de montaje fabrique
alternativamente diversas versiones de un mismo modelo, adaptándose a la
demanda existente en cada momento.

#### Medicina

Desde hace varias décadas, las computadoras ayudan a los profesionales
de la medicina en su larga lucha contra la enfermedad. Desde la gestión
administrativa de la pequeña consulta de un médico, hasta la de un gran
hospital, o la ayuda en las exploraciones radiológicas. También ofrecen
una gran ayuda en el campo de la investigación médica, farmacéutica,
biológica, química, etc., aspectos todos ellos relacionados con la lucha
de los médicos para conseguir un buen nivel de salud en las personas. En
la medicina especializada, las computadoras reducen la posibilidad de
error en el diagnóstico y aceleran su formulación, con lo que se gana un
tiempo que a veces puede ser vital para el paciente. También ponen al
alcance del personal médico un gran banco de datos con los historiales
médicos, tratamientos de enfermedades, estadísticas nacionales de
epidemias, etcétera. Se utilizan también sistemas expertos, que son
auténticos especialistas en la materia para la que están programados.

#### Sistemas domésticos

Se conocen ya los primeros modelos de sistemas domésticos de control.
Consisten en mecanismos de control remoto diseñados para su uso en
domicilios particulares. Con un sistema de este tipo y una instalación
adecuada de periféricos, es posible controlar y operar sobre todos o
casi todos los elementos de la casa. El sistema dispone de una unidad
central que permite programar digital o gráficamente las funciones
deseadas y ordenar su ejecución de manera inmediata o diferida. Una
instalación o red especial transmite las señales codificadas que emite
un módulo central. Desde este módulo se pueden conectar los
electrodomésticos, encender o apagar las luces, poner en marcha la
cafetera, regular la calefacción o el aire acondicionado, supervisar el
funcionamiento de la lavadora o del horno de cocina, preparar el baño a
la temperatura y hora prefijadas. Los sistemas domésticos de control
también pueden realizar tareas no requeridas de modo específico, como
detectar fugas de gas y prevenir al usuario o cerrar la llave de paso,
avisar a los bomberos en caso de fuego, controlar un sistema de
seguridad, etc.

#### Simulación y análisis de datos

La simulación es una de las maneras más importantes en que las
computadoras ayudan al hombre a realizar planificaciones para el futuro.
Mediante esta técnica se construye un modelo de un determinado proceso a
base de relaciones matemáticas y se prueba antes de que el proceso se
ponga en marcha de manera definitiva. La computadora es una herramienta
casi imprescindible en los estudios de simulación, al poder generar en
muy poco tiempo muchos miles (o quizá millones) de condiciones
diferentes que pueden tener influencia en el modelo, así como también
registrar y ordenar todos los resultados obtenidos. Por ejemplo,
procesos tales como las operaciones dentro de un reactor nuclear, el uso
de una nueva carretera, el cambio de precio de un producto, la posible
evolución de una estrella o galaxia, etc., pueden simularse con una
computadora, para que ayude a determinar qué efectos causará la
concurrencia de unas determinadas condiciones en el modelo real.

#### Animación

La técnica de la animación por computadora proporciona a los medios
audiovisuales muchas posibilidades de manipulación de imágenes y de
producción de efectos especiales. Una de las primeras películas rodadas
con la ayuda de la computadora fue La guerra de las galaxias, con
efectos especiales muy logrados; más tarde tuvimos ocasión de presenciar
el filme de Walt Disney llamado Tron, la primera película realizada casi
totalmente con la técnica de animación por computadora, en la cual los
actores se mueven en un mundo imaginario que representa el interior de
una computadora. Sin embargo cuando se rodó Tron, la aplicación de la
generación de imágenes por computadora en el cine estaba todavía en sus
inicios. Posteriormente se rodó la película Toy Story, en la cual la
totalidad de las imágenes se generó mediante computadoras. Sin embargo,
la animación no se aplica sólo en productos de entretenimiento, sino que
hay otras posibilidades más reales, como películas médicas aplicadas a
la enseñanza en las que se muestra el interior del cuerpo humano; por
ejemplo, el movimiento de la sangre a través de las venas, de las
arterias y del corazón.

No hay que perder de foco la definición de la informática y la sociedad
de la información en la que vivimos, donde se dice que todo es
información y estamos envueltos de ella, y el contar con las
herramientas que nos ayuden a procesar la se vuelve vitales para el
quehacer humano.

La computadora
==============

Al principio las computadoras se usaban para ayudar y facilitar las
tareas que ya se hacían por otros medios, concretamente cálculos
matemáticos (de ahí que los otros nombres que reciben son computador u
ordenador).

Es una máquina o dispositivo electrónico capaz de recibir datos,
procesarlos y entregar los resultados en la forma deseada, ya sea en el
monitor o impresos. Los datos son procesados por instrucciones en forma
de programas.

En términos generales, una computadora es un dispositivo electrónico
usado para procesar datos, de acuerdo con una serie de instrucciones
almacenadas.

Entre algunas de las modalidades en que una computadora procesa datos,
se incluye la realización de cálculos, el ordenamiento de listas de
palabras o números, la modificación de  documentos e imágenes y el
trazado de gráficos.

En una computadora, la mayor parte de las tareas de procesamiento se
realizan en un componente llamado unidad de procesamiento central (CPU,
Central Processing Unit), que suele ser descrito como el "cerebro" de la
computadora y que forma parte de lo que conocemos como hardware,
mientras que los programas conforman el software.

La característica principal que distingue a la computadora de otros
dispositivos similares, como la calculadora no programable, es que es
una máquina de propósito general, es decir, puede realizar tareas muy
diversas, de acuerdo a las posibilidades que brinde los lenguajes de
programación y el hardware.

Antecedentes
------------

Las computadoras no siempre han sido iguales. En realidad existe un
abismo enorme entre las primeras computadoras que se crearon y las
actuales, que se están volviendo cada vez más pequeñas, más rápidas y
más potentes, y son usadas en un número creciente de aplicaciones. Sería
necesario retornar miles de años en la historia de la humanidad para
entender de dónde vino la idea de crear un dispositivo que facilitara al
hombre hacer los cálculos aritméticos requeridos para solucionar
problemas del mundo real, a la vez que logra más exactitud y rapidez. A
continuación se describen los más representativos.

> Blas Pascal. En 1642 construyó la Pascaline, que sólo realiza sumas
    y restas, y ocupa una caja de zapatos. Su diseño se utilizó en las
    calculadoras mecánicas de los años sesenta, que se volvieron
    obsoletas al seguir las calculadoras electrónicas (Leonardo de Vinci
    tuvo una visión 150 años antes).


> Charles Babbage. Creó la Máquina diferencial en 1822, que calculaba
    tablas matemáticas impulsada con vapor, no fue terminada porque se
    cortó el presupuesto en 1842; tenía dos metros de alto, tres de
    longitud y 4 000 partes, pesaba 3 toneladas. En 1833, construyó la
    Máquina analítica, que incluía una unidad de almacenamiento +, -,
    \*, / en 60 operaciones por minuto. Era impulsada por una locomotora
    y ocupaba un campo de fútbol.

    
> Lady Ada Augusta Lovelace. Entre 1835-1850 colabora con Babbage en
    sus investigaciones. Fue hija de Lord Byron y es considerada la
    primera mujer programadora en tarjetas perforadas.

    
> Herman Hollerith. Diseñó la Máquina tabuladora (1887-1890), que
    funcionaba con tarjetas perforadas, acumulaba y clasificaba la
    información. Se utilizó para el censo de 1890, el cual le reditúo 40
    000 dólares y al gobierno de Estados Unidos le ahorró 5 millones de
    dólares. En 1896, Herman fundó la Tabuilating Machine Company, que
    se fusionó en 1911 con otras para crear Computing-Tabulating-
    Recording Company. En 1924, el director general, Thomas J. Watson,
    cambió su nombre a International Bussines Machines Corporation
    (IBM).

    
> EAM (Electromechanical Accounting Machine). Entre 1920 y 1950 se
    crea la Máquina de contabilidad electromecánica. Tecnología con base
    en tarjetas perforadas; se llegó a utilizar carretillas para
    transportar las tarjetas.

    
> Konrad Zuse. En 1941 construyó la primera computadora programable
    Z3,  que resolvía ecuaciones complejas de ingeniería, era controlada
    por tarjetas perforadas y fue la primera que operó con el sistema
    binario.

    
> Atanasoff y Berry. Una antigua patente de un dispositivo, que mucha
    gente creyó que era la primera computadora digital electrónica, se
    invalidó en 1973 por orden de un tribunal federal y oficialmente se
    le dio el crédito a John V. Atanasoff como el inventor de la
    computadora digital electrónica. El doctor Atanasoff, catedrático
     de  la Universidad  Estatal de  Iowa,  desarrolló  la primera
     computadora digital electrónica entre los años de 1937 a 1942.
    Llamó a su invento la computadora Atanasoff-Berry, o solo ABC
    (Atanasoff Berry Computer). Un estudiante graduado, Clifford Berry,
    fue una útil ayuda en la construcción de la computadora ABC.

    
> Howard Aiken. Supervisó el diseño de la MARK I 1944, 1a primera
    computadora electromecánica, de 17 metros de ancho y tres de alto.
    Un adelanto significativo, se construyó con el patrocinio de la IBM
    en la Universidad de Harvard. En lo fundamental, se trataba de una
    serie de calculadoras electromecánicas. En muchos aspectos, similar
    a la máquina analítica de Babbage.

    
> Mauchly y Eckert. En 1946, después de varias conversaciones con el
    doctor Atanasoff, leen apuntes que describían los principios de la
    computadora ABC y desean verla en persona. El doctor John W. Mauchly
    colaboró con J. Presper Eckert Jr. para desarrollar una máquina que
    calculara tablas de trayectoria para el ejército estadounidense. El
    producto final, una computadora electrónica completamente
    operacional a gran escala, se terminó en 1946 y se llamó ENIAC
    (Electronic Numerical Integrator And Computer), o Integrador
    numérico y calculador electrónico. La ENIAC, construida para
    aplicaciones de la Segunda Guerra mundial, se terminó en 30 meses
    por un equipo de científicos que trabajaban bajo reloj. La ENIAC,
    mil veces más veloz que sus predecesoras electromecánicas, irrumpió
    como un importante descubrimiento en la tecnología de la
    computación. Pesaba 30 toneladas, ocupaba un espacio de 450 metros
    cuadrados, llenaba un cuarto de 6 x 12 metros y contenía 18 000
    bulbos, tenía que programarse manualmente conectándola a 3 tableros
    que contenían más de 6 000 interruptores.

    
> John von Neumann, que en 1945 había trabajado con Eckert y Mauchly
    en la Universidad de Pennsylvania, publicó un artículo acerca del
    almacenamiento de programas. El concepto de programa almacenado
    permitió la lectura de un programa dentro de la memoria de la
    computadora y después la ejecución de las instrucciones del mismo
    sin tener que volverlas a escribir. La primera computadora en usar
    el citado concepto fue la llamada EDVAC (Eletronic Discrete-Variable
    Automatic Computer, es decir, Computadora automática electrónica de
    variable discreta), desarrollada por von Neumann, Eckert y Mauchly.
    Los programas almacenados dieron a las computadoras una flexibilidad
    y confiabilidad tremendas, haciéndolas más rápidas y menos sujetas a
    errores que los programas mecánicos.
    
    
> La IBM 650. Fue hasta que ocurrió el éxito de la UNIVAC1 cuando la
    IBM se decidió a desarrollar y comercializar computadoras. La IBM
    650 se diseñó como una actualización lógica de las máquinas de
    tarjetas perforadas. La gerencia de IBM superó las ventas calculadas
    de 50 unidades –número mayor que el total de las computadoras
    instaladas en los Estados Unidos en aquel entonces–; de hecho,
    vendió 1 000 de ellas. Lo demás es historia.

### Generaciones de las computadoras 

El desarrollo de las computadoras suele dividirse en generaciones. El
criterio para determinar cuándo se da el cambio de una generación a otra
no está claramente definido, pero resulta aparente que deben cumplirse
al menos dos requisitos estructurales:

1.  Forma en que están construidas: que hayan tenido cambios
    sustanciales.
2.  Forma en que el ser humano se comunica con ellas: que haya
    experimentado progresos importantes.

#### Primera generación

Esta primera etapa abarcó la década de 1950. Las máquinas de esta
generación cumplen los requisitos antes mencionados de la siguiente
manera:

1.  Por medio de circuitos de tubos de vacío.
2.  Mediante la programación en lenguaje de máquina (lenguaje binario).

> Estas máquinas son grandes y costosas (del orden de decenas o
    cientos de miles de dólares).

> Usaban tubos al vacío para procesar información.

> Utilizaban tarjetas perforadas para entrar los datos y los
    programas.

> Requerían cilindros magnéticos para almacenar información e
    instrucciones internas.

#### Segunda generación

Se acercaba la década de 1960 y las computadoras seguían en constante
evolución, reduciendo de tamaño y aumentando sus capacidades de
procesamiento. Al mismo tiempo, se iba definiendo con mayor claridad
toda una nueva ciencia: la de comunicarse con las computadoras, que
recibirá el nombre de programación de sistemas.

En esta etapa puede hablarse ya de la segunda generación de
computadoras, que se caracteriza por los siguientes aspectos
primordiales:

1.  Están construidas con circuitos de transistores.
2.  Se programan en nuevos lenguajes llamados de alto nivel.

> En general, las computadoras de la segunda generación son de tamaño
    más reducido y de costo menor que las anteriores.

> Usaban transistores para procesar información.

> Los transistores eran más rápidos, pequeños y confiables que los
    tubos al vacío. Utilizaban pequeños anillos magnéticos para
    almacenar información e instrucciones.

> Se mejoraron los programas de computadoras que fueron desarrollados
    durante la primera generación.

#### Tercera generación 

Con la aparición de nuevas y mejores maneras de comunicarse con las
computadoras, junto con los progresos en la electrónica, surge lo que se
conoce como tercera generación de computadoras, a mediados de la década
de 1960. Se puede decir que se inaugura con la presentación, en abril de
1964, de la serie 360  de IBM.

Las características estructurales de la tercera generación consisten en:

1.  Su fabricación electrónica está basada en circuitos integrados
    (agrupamiento de circuitos de transistores grabados en pequeñísimas
    placas de silicio).
2.  Su manejo es por medio de los lenguajes de control de los sistemas
    operativos.

> Las grandes computadoras reciben en inglés el nombre de mainframes,
    que significa, precisamente, gran sistema.

> Entre las máquinas de la tercera generación hay algunas dedicadas a
    propósitos especiales, que manejan cientos de millones de números en
    representación decimal y requieren diseños específicos para ser
    resueltos.

> Se desarrollaron circuitos integrados para procesar información.

> Se desarrollaron los "chips" para almacenar y procesar la
    información. Un "chip" es una pieza de silicio que contiene los
    componentes electrónicos en miniatura llamados semiconductores.
> Otra vez las computadoras se tornan más pequeñas, ligeras y
    eficientes.

> Consumían menos electricidad, por lo tanto, generaban menos calor.

#### Cuarta generación 

El adelanto de la microelectrónica prosigue a una velocidad
impresionante y ya para el año de 1972 surge en el mercado una nueva
familia de computadoras integradas de alta densidad, que reciben el
nombre de microprocesadores. Los microprocesadores que se diseñan con
base en estos circuitos son extremadamente pequeños y baratos, por lo
que su uso se extiende al mercado de consumo  industrial. Hoy en día,
hay microprocesadores en muchos aparatos de uso común, como relojes,
televisores, hornos, juguetes, etc. Y, naturalmente, en toda nueva
generación de máquinas, aunque sólo en lo que respecta al equipo físico
(requisito A mencionado con anterioridad), puesto que en el otro aspecto
(requisito B, para determinar el cambio de una generación a otra) no ha
habido progresos de esta magnitud, aunque los cambios producidos tampoco
son despreciables.

> Se desarrolló el microprocesador.

> Se colocan más circuitos dentro de un chip.

> Se reemplaza la memoria de anillos magnéticos por la memoria de
    chips de silicio.

> Se desarrollan las microcomputadoras, o sea, las computadoras
    personales (PC).

#### Quinta generación 

En vista de la acelerada marcha de la microelectrónica, la sociedad
industrial se ha dado a la tarea de poner también a esa altura el
desarrollo de software y  los sistemas con los que se manejan las
computadoras. Ha surgido un interesante fenómeno de competencia
internacional por el dominio del gigantesco mercado de la computación,
en la que se perfilan los líderes que, sin embargo, no han podido
alcanzar el nivel que se desea: la capacidad de comunicarse con la
computadora mediante el lenguaje natural y no a través de códigos o
lenguajes de control especializados.

Japón lanzó en 1983 el llamado “programa de la quinta generación de
computadoras”, con los objetivos explícitos de producir máquinas con
innovaciones reales en los dos criterios mencionados. Y en Estados
Unidos ya está en actividad  un programa de desarrollo que persigue
objetivos semejantes, que pueden  resumirse de la siguiente manera:

1.  Procesamiento en paralelo mediante arquitecturas y diseños
    especiales y circuitos de gran velocidad.
2.  Manejo de lenguaje natural y sistemas de inteligencia artificial.

El futuro previsible de la computación es muy interesante, y se puede
esperar que esta ciencia siga siendo objeto de atención prioritaria de
gobiernos y de la sociedad de manera conjunta.

Hardware y Software 
-------------------

Cuando nos referimos a un sistema de cómputo, debemos considerar los
cuatro elementos básicos que lo componen:  

> Hardware
  
> Software
  
> Datos
  
> Usuario

Resulta interesante recordar el significado de la palabra Sistema, el
cual refiere a un conjunto de elementos que están íntimamente
interrelacionados y buscan un objetivo en común.

Con la anterior definición de sistema es que ahora podemos inferir la
definición de un sistema de cómputo, la cual podemos considerarla como
al conjunto de elementos electrónicos (hardware) que interactúan entre
sí, para procesar y almacenar datos o información de acuerdo a una serie
de instrucciones (software).

Tanto el hardware como el software son indispensables para trabajar, ya
que podemos tener la parte física, pero sin las aplicaciones simplemente
no se haría nada y viceversa. Por eso ambos deben ir entrelazados.

Los datos son unidades o elementos que por sí solos no cumplen función
alguna, pero que al ser introducidos por un usuario a la computadora son
procesados en un archivo.

Los sistemas de cómputo manejan una gran diversidad en cuanto al tamaño,
costo, desempeño, funcionalidades, periféricos, etc.

El hardware es el cuerpo de la computadora y el software el alma.

> El hardware consiste en dispositivos electrónicos interconectados
    que podemos usar para controlar la operación, así como la entrada y
    la salida de la computadora; además, se refiere a los dispositivos
    físicos que conforman el sistema de computación. Cuando la gente
    habla de una computadora, por lo general se refiere al hardware.

> El término software concierne al conjunto de instrucciones
    electrónicas que le dicen al hardware qué debe hacer. Estos
    conjuntos de instrucciones también se conocen como programas y cada
    uno tiene un propósito específico, es decir, los programas hacen que
    la computadora ejecute las funciones deseadas.

### Componentes de una computadora

#### Unidad central de procesamiento (CPU) 

> El término unidad central de procesamiento (Central Processing Unit:
    CPU) se refiere al hardware de procesamiento de la computadora, ya
    sea que conste de un solo chip o de varias tarjetas de circuitos.

> Este “órgano vital” ocupa un espacio sorprendentemente pequeño en
    una PC.

> El procesador es como el cerebro de la computadora; es la parte que
    organiza y lleva a cabo las instrucciones que provienen del usuario
    o del software.

> Éste se localiza en la tarjeta madre, que es el tablero de circuitos
    que conecta la CPU a todos los otros dispositivos de hardware.

> Cada CPU tiene, al menos, dos partes básicas: la unidad de control y
    la unidad lógica  aritmética.

#### Unidad de control 

> La unidad de control se refiere a las instrucciones o conjuntos de
    instrucciones que enumeran todas las operaciones que puede realizar
    la CPU.

> Cada instrucción, en el conjunto de instrucciones, es expresada en
    microcódigo, una serie de direcciones básicas que le dicen a la CPU
    cómo ejecutar operaciones más complejas.

> La unidad de control es el núcleo del procesador.

> La unidad de control tiene tres funciones básicas:

1.  Leer e interpretar las instrucciones de los programas.
2.  Dirigir la operación de los componentes internos del procesador.
3.  Controlar el flujo de entrada y salida de programas y datos en RAM.

#### Unidad aritmético lógica (UAL) 

> Además de establecer secuencias ordenadas y cambiar éstas, la
    computadora puede realizar sólo dos tipos de operaciones:
    operaciones aritméticas y operaciones lógicas.

> Las operaciones aritméticas incluyen suma, resta, multiplicación y
    división.

> Las operaciones lógicas incluyen comparaciones, cómo determinar
    cuándo un número es igual a, mayor que o menor que otro número.
    Asimismo, cada operación lógica tiene un puesto.

> La unidad aritmética lógica (UAL) incluye un grupo de registros,
    ubicaciones de memoria de alta velocidad construidas directamente en
    la CPU que se usan para conservar los datos que se están procesando
    en este momento, realiza todos los cálculos y las operaciones
    lógicas.

> Los resultados se colocan en un registro llamado acumulador.

#### Memoria principal (RAM, ROM y EPROM) 

> La memoria es el espacio que necesita la CPU para poder guardar los
    programas y los datos que se manipulan mientras están en uso.

> Desde el punto de vista físico, la memoria consiste en chips, ya sea
    en la tarjeta madre o en un pequeño tablero de circuitos conectados
    a ésta.

> Tal memoria electrónica permite a la CPU almacenar y recuperar datos
    rápidamente.

RAM. Se le llama memoria de acceso aleatorio (Random Access Memory:
RAM). Su propósito es conservar programas y datos mientras están en uso.
Una computadora no tiene que buscar su memoria entera cada vez que
necesita encontrar datos, ya que la CPU almacena y recupera cada pieza
de datos usando una dirección de memoria. Éste es un número que indica
la ubicación en los chips de memoria.

ROM. Se llama memoria de sólo lectura (Read Only Memory). La ROM
contiene un conjunto de instrucciones de inicio que aseguran que el
resto de la memoria esté funcionando de manera apropiada; verifica los
dispositivos de hardware y busca un sistema operativo en las unidades de
disco de la computadora; y se fabrican en varias configuraciones no
volátiles (PROM, EPROM, EEPROM), de acuerdo con la mayor o menor
facilidad para regrabarlas (aunque únicamente se emplean para lectura y
son grabadas por el fabricante de la computadora, no por el usuario).
Así, los cambios requeridos en la memoria PROM son más sencillos de
realizar, ya que simplemente se saca el circuito, se borra el programa
que contiene (que está codificado en lenguaje máquina) mediante una
lámpara de luz ultravioleta  y se vuelve a grabar con el nuevo programa
(de hecho, para lograr esto se emplea una variante de PROM que se puede
borrar y reprogramar, la cual recibe el nombre de EPROM). La ROM es un
tipo de memoria especial llamada de sólo lectura, que el usuario no
puede modificar.

#### Memorias caché (de la UAL, de video y otras)

Memoria caché. La memoria caché es similar a la RAM, excepto que es muy
rápida  si la comparamos con la memoria normal, y se usa en forma
diferente. Cuando un programa está corriendo y la CPU necesita leer
datos o instrucciones desde la RAM, la CPU verifica primero para ver si
los datos están en la memoria caché. Si los datos que necesita no están
en ésta, lee los datos desde la RAM a sus registros, pero también carga
una copia de los datos en la memoria caché. La siguiente vez que la CPU
necesite los mismos datos, los encontrará en la memoria caché y ahorrará
el tiempo necesario para cargar los datos desde la RAM.

RAM de video. En la actualidad, la mayor parte de los controladores de
video también incluyen al menos 2MB de RAM de video o VRAM. (Ésta es una
adición a la RAM que está conectada a la CPU.) La VRAM es de “doble
puerto”, lo que significa que puede enviar una pantalla de datos al
monitor mientras, al mismo tiempo, recibe la siguiente pantalla de datos
de la CPU; es más rápida y más costosa que la DRAM (RAM dinámica). Los
usuarios con monitores grandes o con mayores necesidades gráficas por lo
general desearán más de 2MB de VRAM.

Memoria (UAL) Coprocesador matemático. Un coprocesador matemático es un
chip diseñado en forma especial para manejar operaciones matemáticas
complicadas. El coprocesador matemático es un procesador especializado
para trabajar exactamente con decimales. Puede ejecutar rutinas
aritméticas mucho más rápido que la UAL debido a que usa aritmética de
punto flotante, una técnica de cómputo que traduce los números a
notación científica.

#### Bus 

El término bus se refiere a las rutas o caminos entre los componentes de
una computadora. Hay dos buses principales en una computadora:

El bus de datos. Es una ruta eléctrica que conecta a la CPU, la memoria
y los otros dispositivos de hardware en la tarjeta madre. En realidad,
el bus es un grupo de cables paralelos. El número de cables en el bus
afecta la velocidad a la que pueden viajar los datos entre los
componentes del hardware. Cada cable puede transferir un bit a la vez,
un bus de ocho cables puede mover ocho bits a un tiempo, lo cual es un
byte completo. Un bus de 16 bits puede transferir dos bytes y un bus de
32 bits puede transferir cuatro bytes a la vez.

El bus de direcciones. Es un juego de cables similar al bus de datos que
conecta la CPU y la RAM y lleva las direcciones de memoria. El bus de
direcciones es importante porque el número de cables en éste determina
la cantidad máxima de direcciones de memoria.

Todas las señales eléctricas se desplazan en un bus eléctrico común; el
término bus se deriva de su pariente con ruedas, ya que los pasajeros de
ambos tipos de buses pueden bajarse en cualquier parada. En las
computadoras, las paradas del bus se pueden realizar en la unidad de
control, la unidad aritmético lógica, la memoria (RAM, ROM) y los
controladores de dispositivos, que controlan la operación de los
dispositivos periféricos.

El bus es la ruta común a través de la cual el procesador envía y recibe
datos y comandos del almacenamiento primario y secundario, así como
todos los dispositivos periféricos de entrada/salida en lugar de abordar
el bus hacia el centro o a las colonias; los bits que viajan entre RAM,
la memoria caché y el procesador se suben en el bus de direcciones y en
el bus de datos. Las direcciones de origen y destino se envían en el bus
de direcciones para identificar una ubicación específica en memoria;
después los datos y las instrucciones se transfieren por el bus de datos
hacia esa ubicación o desde ella.

#### Reloj

Toda microcomputadora tiene un reloj de sistema, pero el propósito
principal del reloj no es mantener la hora del día. Como la mayor parte
de los relojes de pulsera modernos, el reloj es accionado por un cristal
de cuarzo. Cuando se aplica electricidad, las moléculas en el cristal
vibran millones de veces por segundo, con un ritmo que nunca cambia. La
velocidad de la vibración es determinada por el grosor del cristal. La
computadora usa las vibraciones del cuarzo en el reloj del sistema  para
medir sus operaciones de procesamiento.

El corazón de la PC (computadora personal) es el oscilador de cristal y
sus latidos son los ciclos de reloj. El oscilador de cristal regula la
frecuencia de la ejecución de las instrucciones dentro del procesador.
La velocidad del procesador de una microcomputadora se clasifica según
la frecuencia de sus oscilaciones, esto es, el número de ciclos de reloj
por segundo. La velocidad de la mayoría de las computadoras personales
actuales se sitúa entre los 133 y 900 megahertz (MHz).

#### Puertos seriales y paralelos

Un puerto es un enchufe en la parte posterior de la computadora que se
usa para conectar dispositivos externos a ésta. Se le llama interfaz a
los elementos en  pantalla que permiten al usuario interactuar con el
software.

Una interfaz paralela es una conexión donde hay ocho o más cables a
través de los cuales pueden fluir los bits de datos de manera
simultánea. La mayor parte de los buses de computadora transfieren 32
bits en forma simultánea. Sin embargo, la interfaz paralela estándar
para dispositivos externos (como impresoras) por lo general transfiere
ocho bits (un byte) a la vez por ocho cables separados.

Con una interfaz serial, los bits de datos se transmiten uno a la vez a
través  de un solo cable (sin embargo, la interfaz incluye cables
adicionales para los bits que controlan el flujo de los datos). Dentro
de la computadora, un chip llamado UART convierte los datos paralelos
del bus en datos seriales que fluyen a través de un cable serial.

En una PC, los dispositivos periféricos externos vienen con un cable y
un conector de varios pins. Para conectar un dispositivo a la PC, se
inserta su conector en un enchufe. El receptáculo, llamado puerto,
constituye un vínculo directo con el bus eléctrico común de la
microcomputadora.

Los puertos seriales facilitan la transmisión serial de datos, un bit a
la vez. El ratón (mouse) por lo general se conecta en un puerto serial.

Los puertos paralelos facilitan la transmisión paralela de datos, esto
es, se transmiten varios bits simultáneamente. Estos puertos constituyen
la interfaz de dispositivos tales como impresoras de alta velocidad,
unidades de respaldo en cinta magnética y otras computadoras.

### Dispositivos periféricos 

#### Memoria secundaria

Proporciona a la CPU una capacidad de almacenamiento adicional que le
permite leer o escribir informaciones que se pueden conservar durante
largo tiempo. Por su carácter universal y limitado, es imposible que la
memoria principal sirva para almacenar información durante más tiempo
que el necesario para ejecutar un programa. Se necesitan, por
consiguiente, memorias auxiliares que puedan almacenar información de
modo permanente o casi permanente. Los dispositivos de almacenamiento
exterior o auxiliar se conocen como memoria de masa por su gran
capacidad de almacenamiento en cintas, discos magnéticos, y se denominan
unidades.

#### Dispositivos de entrada (teclado, mouse, lectoras ópticas y magnéticas, sensores, etcétera) 

> Teclado. El teclado es el principal dispositivo de entrada para
introducir letras, números, símbolos, puntuación y comandos en la
computadora. Es un dispositivo relativamente simple, que consta de más o
menos 100 teclas, cada una de las  cuales envía un código de carácter
diferente a la CPU. Fue uno de los primeros periféricos que se usó con
las PC, y todavía es el más común; nosotros encontraremos un teclado
incorporado o conectado a todas las PC. Los teclados de computadora por
lo general incluyen teclas numéricas, alfanuméricas, de movimiento del
cursor, modificadoras y de función, así como otras teclas especiales.

> Mouse. Es un dispositivo de entrada que rueda sobre una superficie plana
 (por lo general en el escritorio) y controla el puntero. El puntero es
un objeto en la pantalla (normalmente una flecha), que se usa para
seleccionar texto, tener acceso a menús, mover archivos o interactuar
con programas, archivos o datos que aparece en la pantalla. En lugar de
obligarnos a teclear o emitir comandos desde el teclado,  el mouse y los
sistemas operativos basados en éste nos permiten elegir comandos desde
menús y cuadros de diálogo fáciles de usar.

> Lápices. Los sistemas basados en lápices usan un lápiz electrónico como
el principal dispositivo de entrada. Se sostiene el lápiz en la mano y
se escribe en una almohadilla especial o en forma directa en la
pantalla. También se puede usar el lápiz como un dispositivo de
señalamiento, como un mouse, para seleccionar comandos. Es importante
darse cuenta de que la pantalla es el dispositivo de entrada, no el
lápiz. La pantalla detecta presión, luz o una carga electrostática que
proviene del lápiz y luego almacena la posición de esa señal.

> Pantalla sensible al tacto. Permite al usuario señalar directamente en
la visualización de la computadora, generalmente para seleccionar de un
menú de opciones en la pantalla. La mayor parte de las computadoras con
pantallas sensibles al tacto usan sensores en ésta, o cerca de ella, que
pueden detectar el tacto de un dedo, sintiendo la presión o el calor de
éste.

> Lectores de códigos de barras. Después del teclado, es el dispositivo de
entrada usado en forma más amplia. El tipo más común de lector de
códigos de barras es el modelo de cama plana, el cual se encuentra por
lo común en supermercados y tiendas departamentales. Estos dispositivos
convierten un código de barras, que es un patrón de barras impresas en
productos, en un número de producto emitiendo un rayo de luz, con
frecuencia un rayo láser, que refleja la imagen del código de barras y
convierte estos patrones de barras individuales en dígitos numéricos.

> Escáneres de imágenes y reconocimiento de caracteres (OCR). El lector de
códigos de barras en realidad es un tipo especial de escáner de
imágenes. Los escáneres de imágenes convierten electrónicamente
cualquier imagen al dirigir una luz hacia la imagen y sentir la
intensidad del reflejo en cada punto. El escáner de imágenes es útil
porque traduce imágenes impresas a un formato electrónico que puede
usarse almacenado en la memoria de una computadora.

> Micrófonos y reconocimiento de voz. Los micrófonos se están volviendo
cada vez más importantes como dispositivos de entrada. Para este tipo de
entrada acústica lo que se requiere es una grabación digitalizada. Todo
lo que necesitamos para realizar una grabación así, es un micrófono (o
algún otro dispositivo de entrada acústica, como un reproductor de
discos compactos) y una tarjeta de sonido que convierta la señal
eléctrica del micrófono en señal digitalizada que la computadora pueda
almacenar y procesar. Convertir la voz en texto es una capacidad
conocida como reconocimiento de voz (o reconocimiento del habla). Con
ella, podemos hablar a la computadora en lugar de mecanografiar, y
podemos controlarla con comandos simples, como “abrir” o “cancelar”.

> Entrada de video. Los usuarios de computadora están añadiendo a sus
sistemas capacidades de entrada de video en grandes cantidades.
Aplicaciones como las videoconferencias permiten a los usuarios emplear
imágenes de video de movimiento completo, capturadas por una cámara de
video PC, y transmitirlas a un número limitado de receptores en una red
o a todo el mundo en Internet.

> Trackball. Dispositivo de entrada que funciona como un ratón invertido,
el cual consiste de una cubierta estacionaria que contiene una bola
móvil que se opera con la mano; se utiliza con frecuencia en
computadoras laptop y juegos de video.

#### Bandas magnéticas 

Las bandas magnéticas que se encuentran en el reverso de las tarjetas de
crédito y gafetes de identificación, ofrecen otro medio de introducción
de datos. Las bandas magnéticas están codificadas con los datos
correspondientes a la aplicación, contienen más datos por unidad de
superficie que los caracteres impresos y el código de barras.

La versión mejorada de las tarjetas de banda magnética son las tarjetas
inteligentes, las cuales son similares en aspecto a las demás, pero
contienen un microprocesador en cuya memoria conservan siempre ciertos
datos personales y de seguridad.

#### Sistemas de entrada visual 

Los sistemas de entrada visual son adecuados para tareas más
especializadas, en las que sólo se encuentran unas cuantas imágenes.
Estas tareas por lo general son simples y monótonas, como la inspección.
Un sistema digital de inspección visual en una línea de ensamble rechaza
aquellas piezas que no satisfacen ciertas especificaciones de calidad.
El sistema visual realiza inspecciones rudimentarias de calibración y
después indica a la computadora que ejecute  la acción correspondiente.

#### Dispositivos de salida (pantalla, impresora, graficadora, etcétera) 

> Monitor. Es el más importante, porque es el dispositivo de salida con el
que los usuarios interactúan con más frecuencia. Dos elementos
importantes determinan la calidad de la imagen que despliega un monitor:
el monitor mismo y el controlador de video. Se usan dos tipos básicos de
monitores con las PC. El primero es el monitor típico que vemos en una
computadora de escritorio; se parece a un aparato de televisión y
funciona en la misma forma. El segundo tipo, conocido como monitor de
pantalla plana, se usa con las computadoras notebook.

> Impresora. Dispositivo de salida que produce una copia impresa en papel.
Hay muchos tipos de impresoras:

> Plotter. Es como una impresora en vista de que produce imágenes en
papel, pero el plotter se usa para imprimir imágenes de formato grande,
 como dibujos de construcción o de ingeniería creados en un sistema CAD.

> Sistemas de sonido. Las bocinas y su tecnología asociada son sistemas
clave de salida. Cuando se compra una PC multimedia, se obtiene una
máquina que incluye una unidad de CD-ROM, un controlador de video de
alta calidad, bocinas y una tarjeta de sonido. Las bocinas conectadas a
estos sistemas son parecidas a las que se conectan a un sistema
estereofónico. La única diferencia es que generalmente son más pequeñas
y contienen sus propios amplificadores. La tarjeta de sonido convierte
los sonidos digitales en corriente eléctrica que es enviada a las
bocinas. El sonido se define como la presión de aire que varía a lo
largo del tiempo.

#### Dispositivos de entrada/salida (cintas y discos) 

Hoy en día, para almacenar datos, se usan dos tecnologías principales:
almacenamiento magnético y óptico. Aunque, por lo general, los
dispositivos que almacenan datos emplean una u otra, algunos combinan
ambas tecnologías.

Los tipos principales de almacenamiento magnético son:

> Disquetes.

> Discos duros.

> Discos duros removibles.

> Cinta magnética.

Los tipos principales de almacenamiento óptico son:

> Disco compacto de memoria de sólo lectura (CD-ROM).

> Unidades escribir una vez, leer muchas (write once, read many;
    WORM).

> Unidades regrabables de cambio de fase.

> Disco magneto-ópticos.

> Unidades ópticas.

Las unidades de disquete y las unidades de disco duro se conocen como
almacenamiento magnético porque registran los datos como campos
magnéticos. También se encuentran la unidad de cinta, la cual es un
agregado que se usa a menudo para crear una copia de respaldo de un
disco duro, preservando el contenido en caso de que el disco duro se
dañe.

Las técnicas de almacenamiento óptico usan la precisión exacta que sólo
es posible con rayos láser. Un láser usa un rayo de luz reducido,
concentrado, enfocado y dirigido con lentes, prismas y espejos. El foco
conciso del rayo láser es posible debido a que toda la luz tiene la
misma longitud de onda.

### Sistema operativo 

El Sistema Operativo (SO) es el programa de control maestro de la
computadora. El SO proporciona las herramientas (comandos) que nos
permiten interactuar con la PC. Cuando emitimos un comando, el SO lo
traduce en un código que la máquina puede usar. El SO también asegura
que los resultados de las acciones sean desplegados en pantalla,
impresos, etcétera.

El sistema operativo es el núcleo de toda actividad de software,
monitorea y controla toda la entrada y salida, así como la actividad de
procesamiento dentro del sistema de computadora. Uno de los programas
del sistema operativo, llamado por  lo general el kernel, carga a otros
programas del SO y de aplicaciones en RAM, conforme se van necesitando.
El kernel se carga en RAM al iniciarse el sistema y permanece en el
residente, es decir, está disponible en RAM hasta que se apaga la
computadora.

Todo el hardware, desde el teclado hasta el programa de procesamiento de
palabras, está bajo el control del sistema operativo; éste determina
cómo se asigna a los programas la valiosa RAM, establece las prioridades
para manejar las tareas y administra el flujo de información que entra y
sale del procesador.

##### Tipos de sistemas operativos 

Existen plataformas un solo usuario y multiusuario debido a los
objetivos y orientación de los tipos de sistemas operativos. Las
plataformas de un solo usuario más utilizadas combinan cualquier
microcomputadora compatible con PC, ya sea  con el sistema operativo
MS-DOS o Windows 95, y la Macintosh, con su sistema operativo System.

PC compatibles con MS-DOS. Desde 1990, la plataforma preferida por la
mayoría de los usuarios de PC ha estado definida por las
microcomputadoras que son compatibles funcionalmente con la arquitectura
IBM PC-AT de 1994 (la familia Intel de microprocesadores) y que ejecutan
el sistema operativo MS-DOS. Esta plataforma domina por estas razones:

> La mayoría de los usuarios trabaja en un ambiente de un solo usuario,
con una aplicación a la vez.

> Se han creado miles de paquetes de software para esta plataforma.

> Millones de personas están familiarizadas con esta plataforma y tienen
reticencias para cambiarla.

> Los usuarios han hecho una tremenda inversión en el software y el
hardware que se ejecuta en esta plataforma.

> Plataformas multiusuario, de nivel PC, se dividen en dos grupos: las que
están basadas en UNIX y las que posibilitan la computación de trabajo en
grupo.

Los objetivos de los sistemas operativos se aplican a todos los sistemas
de computación; sin embargo, los sistemas operativos de las mainframes y
de las microcomputadoras difieren considerablemente en complejidad y
orientación. En la mainframe, el sistema operativo multiusuario coordina
numerosos procesadores de funciones especiales y monitorea la
interacción con cientos, y quizá miles, de terminales de una red. En
cambio, la mayoría de los sistemas operativos para microcomputadoras se
diseña básicamente para soportar a un solo usuario en una sola
microcomputadora.

El sistema operativo realiza las siguientes funciones:

> Provee las instrucciones para desplegar los elementos en pantalla
    con los cuales interactuamos. De manera colectiva, estos elementos
    se conocen como interfaz del usuario.

> Carga programas (como programas de procesamiento de palabras y de
    hoja de cálculo) en la memoria de la computadora para que podamos
    usarlos.

> Coordina cómo trabajan los programas con la CPU, RAM, teclado,
    ratón, impresora y demás hardware, así como otro software.

> Administra la forma en que se almacena la información y se recupera
    de los discos.

> Facilita la comunicación entre el sistema de computación y la gente
    que lo maneja. La interfaz a través de la cual los usuarios emiten
    los comandos relacionados con el sistema es parte del sistema
    operativo.

> Facilita la comunicación entre los componentes del sistema de
    computación. El sistema operativo administra los recursos del
    sistema para maximizar el rendimiento, esto es, la cantidad de
    procesamiento entre la unidad de tiempo.

> Minimiza el tiempo necesario para ejecutar un comando del usuario.
    En los sistemas interactivos actuales, cualquier reducción del
    tiempo de espera por pequeña que sea, rinde dividendos en la
    eficiencia del usuario.

> Optimiza el uso de los recursos del sistema de computación. El
    sistema operativo está detectando constantemente cuáles tareas deben
    llevarse a cabo y  qué recursos (procesador, RAM y dispositivos
    periféricos) están disponibles para realizarlas. Cada milisegundo,
    el procesador toma decisiones acerca de cuáles recursos debe asignar
    a determinadas tareas.

### Representación interna de datos 

#### Representación binaria de datos 

En una computadora, todos los datos deben ser reducidos a interruptores
eléctricos. Un interruptor sólo tiene dos estados posibles, “encendido”
y “apagado”, así que únicamente tiene dos símbolos numéricos: 0
representa “apagado” y 1 representa “encendido”. Ya que sólo hay dos
símbolos, se dice que las computadoras funcionan con base 2, lo cual
también se conoce como sistema binario (bi significa dos en latín).

Cuando  una  computadora  necesita  representar  una  cantidad  mayor
 que 1, hace lo mismo que nosotros cuando tenemos que representar una
cantidad mayor que 9: usa dos (o más) dígitos.

Cuando nos referimos a datos computarizados, cada interruptor, esté
 encendido o apagado, se llama bit. El término bit es una contracción de
dígito binario (binary digits). Un bit es la unidad de datos más pequeña
posible.

Después del bit, la siguiente unidad mayor de datos es el byte, el cual
es un grupo de 8 bits. Con un byte, la computadora puede representar
hasta 256 valores diferentes, ya que con 8 dígitos binarios es posible
contar de 0 a 255.

Es sorprendente, pero el potencial (al parecer inagotable) de las
computadoras se basa en sólo dos estados electrónicos: encendido y
apagado. La naturaleza electrónica de la computadora le permite combinar
estos dos estados para representar letras, números, colores, sonidos,
imágenes, formas y mucho más (incluso olores).

#### Códigos de representación de datos (ASCII, etcétera) 

EBCDIC. IBM desarrolló el sistema EBCDIC (se pronuncia “Eb-si-dic”) que
significa Código de intercambio de decimales codificados en binarios
extendidos (Extended Binary Code Decimal Interchange Code). Es un código
de 8 bits que define 256 símbolos. Aún se usa en mainframes y sistemas
de rango medio de IBM, pero rara vez se encuentra en computadoras
personales.

ASCII. Significa Código estándar estadounidense para el intercambio de
información (American Standard Code for Information Interchange).
Actualmente, este juego de caracteres es el más común. Es un código de
127 caracteres; los caracteres del 0 al 31 son de control, del 32 al 64
son caracteres especiales y números, del 65 al 96 son letras mayúsculas
y unos cuantos símbolos, del 97 al 127 son letras minúsculas y unos
pocos símbolos comunes. Hay muchas variaciones que especifican
diferentes juegos de caracteres para los códigos del 128 al 255. La
norma ISO (Organización Internacional de Normas; International Standars
Organization) expandió el juego de caracteres ASCII con la finalidad de
ofrecer diferentes juegos de caracteres para diferentes grupos de
idiomas.

Unicode. Es una norma para representación de datos que está en evolución
y es llamada Norma de código único de caracteres mundiales (Unicode
Worldwide Character Set); proporciona dos bytes (16 bits) para
representar cada símbolo. Con dos bytes, un carácter Unicode podría ser
cualquiera de más de 65 536 caracteres o símbolos diferentes,
suficientes para cada carácter y símbolo en el mundo, incluyendo los
vastos juegos de caracteres chinos, coreanos y japoneses y aquellos que
se encuentran en textos clásicos e históricos conocidos. Es una meta que
vale la pena.

El sistema de codificación de siete bits ASCII es el sistema más
difundido para PC y comunicación de datos. En ASCII, la B y el 3 se
representan digitalmente en la computadora como 1000010 y 0110011,
respectivamente. Las letras, los números y los caracteres especiales se
designan colectivamente como caracteres alfanuméricos, los cuales se
codifican como entrada en una configuración de bits para que la
computadora pueda interpretarlos. La combinación de bits usados para
representar un carácter se llama byte, el código ASCII puede representar
hasta 128 caracteres.

Microsoft Windows usa el sistema de codificación ANSI de 8 bits, norma
desarrollada por el Instituto Nacional de Estándares de Estados Unidos y
que  permite compartir texto entre aplicaciones de Windows. Al igual que
ASCII ampliado de IBM, las primeras 128 claves de ANSI son iguales a las
claves de ASCII, pero las 128 siguientes están definidas para satisfacer
las necesidades de las aplicaciones Windows.

### Unidades de medición

En la informática y en sistemas de cómputo se utilizan diversas unidades
de medición, todo dependerá si se habla de almacenamiento, procesamiento
o transmisión. Comenzaremos por tratar las unidades de almacenamiento.
Con estas unidades medimos la capacidad que tienen los diferentes
dispositivos (discos duros, USB, DVD, etc) de guardar información.

La unidad básica en la informática es el bit o también conocido como
Binary Digit, que representa a un dígito en sistema binario (0 ó 1) con
el que se forma toda la información. Evidentemente esta unidad es
demasiado pequeña para poder contener una información diferente a una
dualidad (abierto/cerrado, si/no), por lo que se emplea un conjunto de
bits (en español el plural de bit NO es bites, sino bits) Después del
bit la unidad que le sigue es el byte, la cual está formada por un
octeto (8 bits). El Kilobyte (KB) está compuesto de 1.024 bytes (no son
1.000 bytes). Debido al mal uso de este prefijo (Kilo, proveniente del
griego, que significa mil), se está utilizando cada vez más el término
definido por el IEC (Comisión Internacional de Electrónica) Kibi o KiB
para designar esta unidad.

El Megabyte (MB) está dejando de ser la unidad de capacidad más
utilizada en Informática. El MB está formado por 1.048.576 bytes (No son
1.000 KB, sino 1.024 KB). Al igual que ocurre con el KB, dado el mal uso
del término, cada vez se está empleando más el término MiB. El Gigabyte
(GB) es la unidad que actualmente más se utiliza. Un GB son 1.024 MB (o
MiB), por lo tanto 1.048.576 KB. Cada vez se emplea más el término
Gibibyte o GiB. El Terabyte (TB) es la unidad de medida que está
empezando a surgir, sobre todo cuando hablamos de disco duros. Un TB son
1.024 GB. Nomenclatura (Sistema Internacional): Byte Kilobyte = KB
Megabyte = MB Gigabyte = GB Terabyte = TB Petabyte = PB Exabyte = EB
Zettabyte = ZB Yottabye = YB Las unidades de procesamiento se miden en
megahercios (Mhz). Un megahercio es igual a un millón de hercios. Un
hercio o hertz es una unidad de frecuencia que equivale a un ciclo o
repetición de un evento por segundo.

En palabras simples significa que un procesador que trabaje a una
velocidad de 500 megahercios es capaz de repetir 500 millones de ciclos
por segundo. En la actualidad, dada la gran velocidad de los
procesadores, la unidad más frecuente es el gigahercio (Ghz), que
corresponde a 1.000 millones de hercios por segundo. Esto es, a mayor
frecuencia de reloj (más megahercios) se supone una mayor velocidad de
procesamiento, eso es cierto a medias, ya que en la velocidad de un
equipo no solo influye la capacidad de procesamiento del procesador,
sino que también influyen los demás componentes, como son: memoria ram,
disco duro, etc. Para el caso de definir las velocidades de transmisión
se suele usar como base el bit, y más concretamente el bit por segundo,
o bps.

 que involucra en su estructura semántica dos términos: información y
automática. Se acuñó en Francia hace 40 años con la intención de definir
el conjunto de procedimientos, métodos, técnicas y otros aspectos
científicos de diferentes áreas que se venían desarrollando y aplicando
al tratamiento de la información con el uso de las computadoras para
resolver problemas económicos, sociales y políticos.

Para definirla decimos que: “Informática es la sistematización racional
de la información”. Consideramos que esta definición ubica a la
informática en una actitud más próxima a una ciencia y en torno a la
información, pero siempre tratada ésta en forma de sistema o sistemas.
Es decir, sistematizar la información es la función básica de la
informática, pero deberá hacerse racionalmente, de lo contrario la
función es incompleta.

Es obvio que para sistematizar la información es necesario el uso de
herramientas que van desde el papel y el lápiz hasta las computadoras
más sofisticadas, dependiendo del volumen de datos que se maneje para
generar la información y los procedimientos que se establezcan para el
procesamiento de los datos.

En Estados Unidos no es muy conocido el término, que se toma como
sinónimo de information technology  (IT) .